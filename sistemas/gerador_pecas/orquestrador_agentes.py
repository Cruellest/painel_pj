# sistemas/gerador_pecas/orquestrador_agentes.py
"""
Orquestrador de Agentes para GeraÃ§Ã£o de PeÃ§as JurÃ­dicas

Coordena os 3 agentes do fluxo:
1. Agente 1 (Coletor): Baixa documentos do TJ-MS e gera resumo consolidado
2. Agente 2 (Detector): Analisa resumo e ativa prompts modulares relevantes
3. Agente 3 (Gerador): Gera a peÃ§a jurÃ­dica usando Gemini 3 Pro
"""

import os
import asyncio
import httpx
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime

from sqlalchemy.orm import Session

from sistemas.gerador_pecas.agente_tjms_integrado import AgenteTJMSIntegrado, ResultadoAgente1
from sistemas.gerador_pecas.detector_modulos import DetectorModulosIA
# NOTA: TemplateFormatacao nÃ£o Ã© mais importado aqui - templates serÃ£o usados apenas para MD->DOCX
from admin.models import ConfiguracaoIA
from admin.models_prompts import PromptModulo


# Modelos padrÃ£o (usados se nÃ£o houver configuraÃ§Ã£o no banco)
MODELO_AGENTE1_PADRAO = "google/gemini-2.5-flash-lite"
MODELO_AGENTE2_PADRAO = "google/gemini-2.5-flash-lite"
MODELO_AGENTE3_PADRAO = "google/gemini-2.5-pro-preview-05-06"
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"

# NOTA: Templates de FormataÃ§Ã£o (TemplateFormatacao) foram removidos do prompt da IA.
# Agora a peÃ§a Ã© gerada diretamente em Markdown.
# Os templates serÃ£o usados futuramente para conversÃ£o MD -> DOCX.


@dataclass
class ResultadoAgente2:
    """Resultado do Agente 2 (Detector de MÃ³dulos)"""
    modulos_ids: List[int] = field(default_factory=list)
    prompt_sistema: str = ""
    prompt_peca: str = ""
    prompt_conteudo: str = ""
    justificativa: str = ""
    confianca: str = "media"
    erro: Optional[str] = None


@dataclass
class ResultadoAgente3:
    """Resultado do Agente 3 (Gerador de PeÃ§a)"""
    tipo_peca: str = ""
    conteudo_markdown: str = ""  # PeÃ§a gerada diretamente em Markdown
    prompt_enviado: str = ""  # Prompt completo enviado Ã  IA (para auditoria)
    tokens_usados: int = 0
    erro: Optional[str] = None


@dataclass
class ResultadoOrquestracao:
    """Resultado completo da orquestraÃ§Ã£o dos 3 agentes"""
    numero_processo: str
    status: str = "processando"  # processando, sucesso, erro, pergunta
    
    # Resultados de cada agente
    agente1: Optional[ResultadoAgente1] = None
    agente2: Optional[ResultadoAgente2] = None
    agente3: Optional[ResultadoAgente3] = None
    
    # Para UI
    pergunta: Optional[str] = None
    opcoes: Optional[List[str]] = None
    mensagem: Optional[str] = None
    
    # Resultado final
    tipo_peca: Optional[str] = None
    conteudo_markdown: Optional[str] = None  # PeÃ§a em Markdown
    url_download: Optional[str] = None
    geracao_id: Optional[int] = None
    
    # Tempos de execuÃ§Ã£o
    tempo_agente1: float = 0.0
    tempo_agente2: float = 0.0
    tempo_agente3: float = 0.0
    tempo_total: float = 0.0


class OrquestradorAgentes:
    """
    Orquestrador que coordena os 3 agentes do fluxo de geraÃ§Ã£o de peÃ§as.
    """
    
    def __init__(
        self,
        db: Session,
        modelo_geracao: str = None
    ):
        """
        Args:
            db: SessÃ£o do banco de dados
            modelo_geracao: Modelo para o Agente 3 (override manual, opcional)
        """
        self.db = db
        self.api_key = os.getenv("OPENROUTER_API_KEY", "")
        
        # Carrega configuraÃ§Ãµes do banco (tabela configuracoes_ia) ou usa padrÃµes
        def get_config(chave: str, padrao: str) -> str:
            config = db.query(ConfiguracaoIA).filter(
                ConfiguracaoIA.sistema == "gerador_pecas",
                ConfiguracaoIA.chave == chave
            ).first()
            return config.valor if config else padrao
        
        self.modelo_agente1 = get_config("modelo_agente1", MODELO_AGENTE1_PADRAO)
        self.modelo_agente2 = get_config("modelo_deteccao", MODELO_AGENTE2_PADRAO)
        self.modelo_agente3 = modelo_geracao or get_config("modelo_geracao", MODELO_AGENTE3_PADRAO)
        
        # MantÃ©m compatibilidade
        self.modelo_geracao = self.modelo_agente3
        
        # Inicializa agentes com modelos configurados
        # O Agente 1 recebe a sessÃ£o do banco para buscar formatos JSON
        self.agente1 = AgenteTJMSIntegrado(
            modelo=self.modelo_agente1,
            db_session=db,
            formato_saida="json"  # Usa formato JSON para resumos
        )
        self.agente2 = DetectorModulosIA(db=db, modelo=self.modelo_agente2)
    
    async def processar_processo(
        self,
        numero_processo: str,
        tipo_peca: Optional[str] = None
    ) -> ResultadoOrquestracao:
        """
        Processa um processo executando os 3 agentes em sequÃªncia.
        
        Args:
            numero_processo: NÃºmero CNJ do processo
            tipo_peca: Tipo de peÃ§a (se jÃ¡ conhecido). Se None, o Agente 2 detecta automaticamente.
            
        Returns:
            ResultadoOrquestracao com o resultado completo
        """
        resultado = ResultadoOrquestracao(numero_processo=numero_processo)
        inicio_total = datetime.now()
        
        try:
            # ========================================
            # AGENTE 1: Coletor TJ-MS
            # ========================================
            print("\n" + "=" * 60)
            print("ðŸ¤– AGENTE 1 - COLETOR TJ-MS")
            print("=" * 60)
            
            inicio = datetime.now()
            resultado.agente1 = await self.agente1.coletar_e_resumir(numero_processo)
            resultado.tempo_agente1 = (datetime.now() - inicio).total_seconds()
            
            if resultado.agente1.erro:
                resultado.status = "erro"
                resultado.mensagem = resultado.agente1.erro
                return resultado
            
            resumo_consolidado = resultado.agente1.resumo_consolidado
            print(f"â±ï¸  Tempo Agente 1: {resultado.tempo_agente1:.1f}s")
            
            # ========================================
            # AGENTE 2: Detector de MÃ³dulos (e tipo de peÃ§a se necessÃ¡rio)
            # ========================================
            print("\n" + "=" * 60)
            print("ðŸ¤– AGENTE 2 - DETECTOR DE MÃ“DULOS")
            print("=" * 60)
            
            inicio = datetime.now()
            
            # Se nÃ£o tem tipo de peÃ§a, o Agente 2 detecta automaticamente
            if not tipo_peca:
                print("ðŸ“‹ Detectando tipo de peÃ§a automaticamente...")
                deteccao_tipo = await self.agente2.detectar_tipo_peca(resumo_consolidado)
                tipo_peca = deteccao_tipo.get("tipo_peca")
                
                if tipo_peca:
                    print(f"âœ… Tipo de peÃ§a detectado: {tipo_peca}")
                    print(f"   Justificativa: {deteccao_tipo.get('justificativa', 'N/A')}")
                    print(f"   ConfianÃ§a: {deteccao_tipo.get('confianca', 'N/A')}")
                else:
                    # Se mesmo assim nÃ£o conseguiu detectar, usa fallback
                    print("âš ï¸ NÃ£o foi possÃ­vel detectar o tipo de peÃ§a automaticamente")
                    tipo_peca = "contestacao"  # Fallback padrÃ£o
                    print(f"   Usando fallback: {tipo_peca}")
            
            resultado.agente2 = await self._executar_agente2(resumo_consolidado, tipo_peca)
            resultado.tempo_agente2 = (datetime.now() - inicio).total_seconds()
            
            if resultado.agente2.erro:
                resultado.status = "erro"
                resultado.mensagem = resultado.agente2.erro
                return resultado
            
            print(f"â±ï¸  Tempo Agente 2: {resultado.tempo_agente2:.1f}s")
            
            # ========================================
            # AGENTE 3: Gerador de PeÃ§a (Gemini 3 Pro)
            # ========================================
            print("\n" + "=" * 60)
            print("ðŸ¤– AGENTE 3 - GERADOR (Gemini 3 Pro)")
            print("=" * 60)
            
            inicio = datetime.now()
            resultado.agente3 = await self._executar_agente3(
                resumo_consolidado=resumo_consolidado,
                prompt_sistema=resultado.agente2.prompt_sistema,
                prompt_peca=resultado.agente2.prompt_peca,
                prompt_conteudo=resultado.agente2.prompt_conteudo,
                tipo_peca=tipo_peca
            )
            resultado.tempo_agente3 = (datetime.now() - inicio).total_seconds()
            
            if resultado.agente3.erro:
                resultado.status = "erro"
                resultado.mensagem = resultado.agente3.erro
                return resultado
            
            print(f"â±ï¸  Tempo Agente 3: {resultado.tempo_agente3:.1f}s")
            
            # Sucesso!
            resultado.status = "sucesso"
            resultado.tipo_peca = tipo_peca
            resultado.conteudo_markdown = resultado.agente3.conteudo_markdown
            
            resultado.tempo_total = (datetime.now() - inicio_total).total_seconds()
            
            print("\n" + "=" * 60)
            print(f"âœ… ORQUESTRAÃ‡ÃƒO CONCLUÃDA")
            print(f"â±ï¸  Tempo Total: {resultado.tempo_total:.1f}s")
            print("=" * 60)
            
            return resultado
            
        except Exception as e:
            resultado.status = "erro"
            resultado.mensagem = f"Erro na orquestraÃ§Ã£o: {str(e)}"
            print(f"âŒ Erro: {resultado.mensagem}")
            return resultado
    
    async def _executar_agente2(
        self,
        resumo_consolidado: str,
        tipo_peca: Optional[str] = None
    ) -> ResultadoAgente2:
        """
        Executa o Agente 2 - Detector de MÃ³dulos
        
        Analisa o resumo e monta os prompts modulares.
        """
        resultado = ResultadoAgente2()
        
        try:
            # Detecta mÃ³dulos de conteÃºdo relevantes via IA
            modulos_ids = await self.agente2.detectar_modulos_relevantes(
                documentos_resumo=resumo_consolidado
            )
            resultado.modulos_ids = modulos_ids
            
            # Carrega mÃ³dulos BASE (sempre ativos)
            modulos_base = self.db.query(PromptModulo).filter(
                PromptModulo.tipo == "base",
                PromptModulo.ativo == True
            ).order_by(PromptModulo.ordem).all()
            
            # Monta prompt do sistema
            partes_sistema = []
            for modulo in modulos_base:
                partes_sistema.append(f"## {modulo.titulo}\n\n{modulo.conteudo}")
            resultado.prompt_sistema = "\n\n".join(partes_sistema)
            
            # Carrega mÃ³dulo de PEÃ‡A (se tipo especificado)
            if tipo_peca:
                modulo_peca = self.db.query(PromptModulo).filter(
                    PromptModulo.tipo == "peca",
                    PromptModulo.categoria == tipo_peca,
                    PromptModulo.ativo == True
                ).first()
                
                if modulo_peca:
                    resultado.prompt_peca = f"## ESTRUTURA DA PEÃ‡A: {modulo_peca.titulo}\n\n{modulo_peca.conteudo}"
            
            # Carrega mÃ³dulos de CONTEÃšDO detectados
            if modulos_ids:
                modulos_conteudo = self.db.query(PromptModulo).filter(
                    PromptModulo.tipo == "conteudo",
                    PromptModulo.ativo == True,
                    PromptModulo.id.in_(modulos_ids)
                ).order_by(PromptModulo.ordem).all()
                
                if modulos_conteudo:
                    partes_conteudo = ["## ARGUMENTOS E TESES APLICÃVEIS\n"]
                    for modulo in modulos_conteudo:
                        partes_conteudo.append(f"### {modulo.titulo}\n{modulo.conteudo}\n")
                        print(f"   âœ“ MÃ³dulo ativado: {modulo.titulo}")
                    resultado.prompt_conteudo = "\n".join(partes_conteudo)
            
            print(f"ðŸ“‹ MÃ³dulos detectados: {len(modulos_ids)}")
            print(f"ðŸ“ Prompt sistema: {len(resultado.prompt_sistema)} chars")
            print(f"ðŸ“ Prompt peÃ§a: {len(resultado.prompt_peca)} chars")
            print(f"ðŸ“ Prompt conteÃºdo: {len(resultado.prompt_conteudo)} chars")
            
            return resultado
            
        except Exception as e:
            resultado.erro = f"Erro no Agente 2: {str(e)}"
            return resultado
    
    async def _executar_agente3(
        self,
        resumo_consolidado: str,
        prompt_sistema: str,
        prompt_peca: str,
        prompt_conteudo: str,
        tipo_peca: str
    ) -> ResultadoAgente3:
        """
        Executa o Agente 3 - Gerador de PeÃ§a (Gemini 3 Pro)
        
        Recebe:
        - Resumo consolidado (do Agente 1)
        - Prompts modulares (do Agente 2)
        
        Gera a peÃ§a jurÃ­dica final.
        """
        resultado = ResultadoAgente3(tipo_peca=tipo_peca)
        
        try:
            # NOTA: Templates de FormataÃ§Ã£o (TemplateFormatacao) NÃƒO sÃ£o mais enviados para a IA.
            # A peÃ§a Ã© gerada diretamente em Markdown, usando o prompt_peca como guia de estrutura.
            # Os templates serÃ£o usados futuramente para conversÃ£o MD -> DOCX.
            
            # Monta o prompt final combinando tudo (SEM template JSON)
            prompt_completo = f"""{prompt_sistema}

{prompt_peca}

{prompt_conteudo}

---

## DOCUMENTOS DO PROCESSO PARA ANÃLISE:

{resumo_consolidado}

---

## INSTRUÃ‡Ã•ES FINAIS:

Com base nos documentos acima e nas instruÃ§Ãµes do sistema, gere a peÃ§a jurÃ­dica completa.

Retorne a peÃ§a formatada em **Markdown**, seguindo a estrutura indicada no prompt de peÃ§a acima.
Use formataÃ§Ã£o adequada: ## para tÃ­tulos de seÃ§Ã£o, **negrito** para Ãªnfase, > para citaÃ§Ãµes.
"""
            
            # Salva o prompt para auditoria
            resultado.prompt_enviado = prompt_completo
            
            print(f"ðŸ“ Prompt montado: {len(prompt_completo)} caracteres (SEM template JSON)")

            # Chama a API do OpenRouter com Gemini 3 Pro
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    OPENROUTER_URL,
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                        "HTTP-Referer": "https://pge-ms.gov.br",
                        "X-Title": "PGE-MS - Gerador de Pecas"
                    },
                    json={
                        "model": self.modelo_geracao,
                        "messages": [
                            {"role": "user", "content": prompt_completo}
                        ],
                        "temperature": 0.3,
                        "max_tokens": 16000
                    }
                )
                
                response.raise_for_status()
                data = response.json()
                
                content = data['choices'][0]['message']['content']
                
                # Remove possÃ­veis blocos de cÃ³digo markdown que a IA pode ter adicionado
                content_limpo = content.strip()
                if content_limpo.startswith('```markdown'):
                    content_limpo = content_limpo[11:]
                elif content_limpo.startswith('```'):
                    content_limpo = content_limpo[3:]
                if content_limpo.endswith('```'):
                    content_limpo = content_limpo[:-3]
                
                resultado.conteudo_markdown = content_limpo.strip()
                
                # Contabiliza tokens
                if 'usage' in data:
                    resultado.tokens_usados = data['usage'].get('total_tokens', 0)
                
                print(f"âœ… PeÃ§a gerada com sucesso em Markdown!")
                print(f"ðŸ“Š Tokens usados: {resultado.tokens_usados}")
                print(f"ðŸ“„ Tamanho da peÃ§a: {len(resultado.conteudo_markdown)} caracteres")
                
                return resultado
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            resultado.erro = f"Erro no Agente 3: {str(e)}"
            return resultado


async def processar_com_agentes(
    db: Session,
    numero_processo: str,
    tipo_peca: Optional[str] = None
) -> ResultadoOrquestracao:
    """
    FunÃ§Ã£o de conveniÃªncia para processar um processo com os 3 agentes.
    """
    orquestrador = OrquestradorAgentes(db=db)
    return await orquestrador.processar_processo(numero_processo, tipo_peca)
