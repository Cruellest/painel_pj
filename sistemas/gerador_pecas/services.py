# sistemas/gerador_pecas/services.py
"""
Servi√ßos do sistema Gerador de Pe√ßas Jur√≠dicas
Utiliza prompts modulares: BASE + PE√áA + CONTE√öDO

Fluxo com 3 agentes:
1. Agente TJ-MS: Baixa documentos e gera resumo consolidado
2. Agente Detector: Analisa resumo e ativa m√≥dulos relevantes
3. Agente Gerador (Gemini 3 Pro): Gera a pe√ßa final
"""

import os
import json
import uuid
import httpx
import re
from typing import Dict, List, Optional
from datetime import datetime
from sqlalchemy.orm import Session

from docx import Document
from docx.shared import Pt, Inches, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH

from sistemas.gerador_pecas.models import GeracaoPeca
from admin.models_prompts import PromptModulo
from admin.models import ConfiguracaoIA
from admin.models_prompt_groups import CategoriaOrdem
from sistemas.gerador_pecas.detector_modulos import DetectorModulosIA

# Flag para indicar se o orquestrador est√° dispon√≠vel (ser√° verificado na primeira chamada)
ORQUESTRADOR_DISPONIVEL = None  # None = n√£o verificado ainda
_OrquestradorAgentes = None  # Cache da classe


def _carregar_orquestrador():
    """Carrega o orquestrador de forma lazy para evitar importa√ß√£o circular"""
    global ORQUESTRADOR_DISPONIVEL, _OrquestradorAgentes
    
    if ORQUESTRADOR_DISPONIVEL is not None:
        return ORQUESTRADOR_DISPONIVEL
    
    try:
        from sistemas.gerador_pecas.orquestrador_agentes import OrquestradorAgentes
        _OrquestradorAgentes = OrquestradorAgentes
        ORQUESTRADOR_DISPONIVEL = True
        print("Orquestrador de agentes carregado com sucesso")
    except Exception as e:
        ORQUESTRADOR_DISPONIVEL = False
        print(f"[WARN] Orquestrador de agentes nao disponivel - modo legado ativo. Erro: {e}")
        import traceback
        traceback.print_exc()
    
    return ORQUESTRADOR_DISPONIVEL


class GeradorPecasService:
    """
    Servi√ßo principal para gera√ß√£o de pe√ßas jur√≠dicas.
    
    Utiliza sistema de 3 agentes:
    - Agente 1 (TJ-MS): Coleta documentos e gera resumo consolidado
    - Agente 2 (Detector): Analisa e ativa m√≥dulos de conte√∫do relevantes
    - Agente 3 (Gemini 3 Pro): Gera a pe√ßa jur√≠dica final
    
    Prompts modulares:
    - BASE: System prompt (sempre ativo)
    - PE√áA: Estrutura espec√≠fica do tipo de pe√ßa (ativado por escolha)
    - CONTE√öDO: Argumentos/teses (ativados por detec√ß√£o de situa√ß√£o)
    """
    
    def __init__(
        self,
        modelo: str = "gemini-3-pro-preview",
        db: Session = None,
        group_id: Optional[int] = None,
        subcategoria_ids: Optional[List[int]] = None
    ):
        self.modelo = modelo
        self.db = db
        self.group_id = group_id
        self.subcategoria_ids = subcategoria_ids or []

        # Diret√≥rio para arquivos tempor√°rios
        self.temp_dir = os.path.join(os.path.dirname(__file__), 'temp_docs')
        os.makedirs(self.temp_dir, exist_ok=True)

        # Inicializar detector de m√≥dulos com configura√ß√µes do banco
        self.detector = None
        self.orquestrador = None
        
        if self.db:
            self.detector = self._inicializar_detector()
            # Inicializa orquestrador se dispon√≠vel (carregamento lazy)
            if _carregar_orquestrador():
                try:
                    self.orquestrador = _OrquestradorAgentes(
                        db=self.db,
                        modelo_geracao=self.modelo,
                        group_id=self.group_id,
                        subcategoria_ids=self.subcategoria_ids
                    )
                    print("Orquestrador de agentes inicializado com sucesso")
                except Exception as e:
                    print(f"[ERRO] Erro ao inicializar orquestrador: {e}")
                    import traceback
                    traceback.print_exc()
                    self.orquestrador = None
    
    def _inicializar_detector(self) -> Optional[DetectorModulosIA]:
        """Inicializa o detector de m√≥dulos com configura√ß√µes do banco"""
        try:
            # Carregar configura√ß√µes do banco
            modelo_config = self.db.query(ConfiguracaoIA).filter(
                ConfiguracaoIA.sistema == "gerador_pecas",
                ConfiguracaoIA.chave == "modelo_deteccao"
            ).first()

            cache_config = self.db.query(ConfiguracaoIA).filter(
                ConfiguracaoIA.sistema == "gerador_pecas",
                ConfiguracaoIA.chave == "cache_ttl_minutos"
            ).first()

            modelo = modelo_config.valor if modelo_config else "gemini-3-flash-preview"
            cache_ttl = int(cache_config.valor) if cache_config else 60

            return DetectorModulosIA(
                db=self.db,
                modelo=modelo,
                cache_ttl_minutes=cache_ttl
            )
        except Exception as e:
            print(f"[ERRO] Erro ao inicializar detector de modulos: {e}")
            return None

    def _carregar_modulos_base(self) -> List[PromptModulo]:
        """Carrega todos os m√≥dulos BASE (sempre ativos)"""
        if not self.db:
            return []
        return self.db.query(PromptModulo).filter(
            PromptModulo.tipo == "base",
            PromptModulo.ativo == True
        ).order_by(PromptModulo.ordem).all()
    
    def _carregar_modulo_peca(self, tipo_peca: str) -> Optional[PromptModulo]:
        """Carrega o m√≥dulo de PE√áA espec√≠fico"""
        if not self.db:
            return None
        return self.db.query(PromptModulo).filter(
            PromptModulo.tipo == "peca",
            PromptModulo.nome == tipo_peca,  # Busca por nome (identificador √∫nico)
            PromptModulo.ativo == True
        ).first()
    
    def _carregar_modulos_conteudo(
        self,
        modulos_ids: List[int] = None,
        group_id: Optional[int] = None,
        subcategoria_ids: Optional[List[int]] = None
    ) -> List[PromptModulo]:
        """
        Carrega m√≥dulos de CONTE√öDO ordenados por categoria e depois por ordem do m√≥dulo.

        Args:
            modulos_ids: IDs dos m√≥dulos detectados pela IA (se None, retorna todos)
            group_id: Grupo principal para prompts modulares (opcional)
            subcategoria_ids: Subcategorias selecionadas para prompts modulares (opcional)
        """
        if not self.db:
            return []

        group_id = self.group_id if group_id is None else group_id
        subcategoria_ids = self.subcategoria_ids if subcategoria_ids is None else subcategoria_ids

        query = self.db.query(PromptModulo).filter(
            PromptModulo.tipo == "conteudo",
            PromptModulo.ativo == True
        )

        # Se IDs espec√≠ficos fornecidos, filtra por eles
        if modulos_ids is not None:
            query = query.filter(PromptModulo.id.in_(modulos_ids))

        if group_id is not None:
            query = query.filter(PromptModulo.group_id == group_id)

        if subcategoria_ids:
            # Filtra m√≥dulos que:
            # 1. Pertencem a pelo menos uma das subcategorias selecionadas, OU
            # 2. N√£o t√™m nenhuma subcategoria associada (s√£o "universais" - sempre eleg√≠veis)
            from admin.models_prompt_groups import PromptSubcategoria
            from sqlalchemy import or_
            query = query.filter(
                or_(
                    PromptModulo.subcategorias.any(PromptSubcategoria.id.in_(subcategoria_ids)),
                    ~PromptModulo.subcategorias.any()
                )
            )

        # Busca todos os m√≥dulos
        modulos = query.all()

        # Ordena por categoria (usando CategoriaOrdem) e depois por ordem do m√≥dulo
        if group_id and modulos:
            # Busca ordem das categorias configurada
            categorias_ordem = self.db.query(CategoriaOrdem).filter(
                CategoriaOrdem.group_id == group_id
            ).all()
            ordem_categorias = {co.nome: co.ordem for co in categorias_ordem}

            # Ordena: primeiro por ordem da categoria, depois por ordem do m√≥dulo
            modulos.sort(key=lambda m: (
                ordem_categorias.get(m.categoria, 9999),  # Categoria sem ordem vai pro final
                m.ordem or 0
            ))

            # Log da ordem dos prompts para debug
            print(f"[ORDEM PROMPTS] Grupo {group_id} - Ordem das categorias: {ordem_categorias}")
            for idx, m in enumerate(modulos):
                cat_ordem = ordem_categorias.get(m.categoria, 9999)
                print(f"  {idx+1}. [{m.categoria}:{cat_ordem}] ordem={m.ordem or 0} - {m.titulo}")
        else:
            # Fallback: ordena apenas por ordem do m√≥dulo
            modulos.sort(key=lambda m: m.ordem or 0)

        return modulos
    
    def _montar_prompt_sistema(
        self,
        tipo_peca: str = None,
        modulos_ids: List[int] = None,
        group_id: Optional[int] = None,
        subcategoria_ids: Optional[List[int]] = None
    ) -> str:
        """
        Monta o prompt de sistema combinando m√≥dulos:
        BASE + PE√áA + CONTE√öDO

        Args:
            tipo_peca: Tipo da pe√ßa (contestacao, recurso, etc)
            modulos_ids: IDs dos m√≥dulos detectados pela IA
            group_id: Grupo principal para prompts modulares (opcional)
            subcategoria_ids: Subcategorias selecionadas para prompts modulares (opcional)
        """
        partes = []

        # 1. M√≥dulos BASE (sempre inclu√≠dos)
        modulos_base = self._carregar_modulos_base()
        for modulo in modulos_base:
            partes.append(f"## {modulo.titulo}\n\n{modulo.conteudo}")

        # 2. M√≥dulo de PE√áA (se tipo especificado)
        if tipo_peca:
            modulo_peca = self._carregar_modulo_peca(tipo_peca)
            if modulo_peca:
                partes.append(f"## ESTRUTURA DA PE√áA: {modulo_peca.titulo}\n\n{modulo_peca.conteudo}")

        # 3. M√≥dulos de CONTE√öDO (baseado em detec√ß√£o por IA)
        modulos_conteudo = self._carregar_modulos_conteudo(
            modulos_ids,
            group_id=group_id,
            subcategoria_ids=subcategoria_ids
        )
        if modulos_conteudo:
            partes.append("## ARGUMENTOS E TESES APLIC√ÅVEIS\n")
            for modulo in modulos_conteudo:
                partes.append(f"### {modulo.titulo}\n{modulo.conteudo}\n")

        # Se n√£o h√° m√≥dulos no banco, usa prompt padr√£o
        if not partes:
            return self._get_prompt_padrao()

        return "\n\n".join(partes)
    
    def _get_prompt_padrao(self) -> str:
        """Retorna prompt padr√£o caso n√£o haja m√≥dulos no banco"""
        return """Voc√™ √© um assistente jur√≠dico especializado da Procuradoria-Geral do Estado de Mato Grosso do Sul (PGE-MS).

Sua fun√ß√£o √© analisar processos judiciais e gerar pe√ßas jur√≠dicas profissionais (contesta√ß√µes, pareceres, recursos).

## DIRETRIZES GERAIS

1. **An√°lise Completa**: Leia TODOS os documentos fornecidos cronologicamente
2. **Identifica√ß√£o Autom√°tica**: Determine qual tipo de pe√ßa √© necess√°ria baseado nos documentos
3. **Fundamenta√ß√£o T√©cnica**: Use jurisprud√™ncia e doutrina quando necess√°rio
4. **Linguagem Forense**: Use linguagem t√©cnico-jur√≠dica adequada
5. **Estrutura Formal**: Siga rigorosamente a estrutura padr√£o de cada tipo de pe√ßa

## TIPOS DE PE√áAS

### CONTESTA√á√ÉO
- Usado quando: Processo em 1¬∫ grau, Estado √© r√©u, prazo de contesta√ß√£o em aberto
- Estrutura: Qualifica√ß√£o ‚Üí Preliminares ‚Üí M√©rito ‚Üí Pedidos

### RECURSO DE APELA√á√ÉO
- Usado quando: Senten√ßa desfavor√°vel ao Estado
- Estrutura: Endere√ßamento ‚Üí Raz√µes Recursais ‚Üí Preliminares ‚Üí M√©rito ‚Üí Pedidos

### CONTRARRAZ√ïES DE RECURSO
- Usado quando: Parte contr√°ria apresentou recurso
- Estrutura: Endere√ßamento ‚Üí Admissibilidade ‚Üí M√©rito ‚Üí Pedidos

### PARECER JUR√çDICO
- Usado quando: An√°lise t√©cnica de quest√£o jur√≠dica espec√≠fica
- Estrutura: Relat√≥rio ‚Üí Fundamenta√ß√£o ‚Üí Conclus√£o

## QUANDO TEM D√öVIDAS

Se voc√™ N√ÉO conseguir determinar com certeza qual pe√ßa gerar ou precisar de informa√ß√µes adicionais, retorne:
```json
{
  "tipo": "pergunta",
  "pergunta": "Qual tipo de pe√ßa voc√™ deseja gerar? Identifiquei que...",
  "opcoes": ["contestacao", "recurso_apelacao", "contrarrazoes", "parecer"]
}
```

## IMPORTANTE

- NUNCA invente fatos n√£o presentes nos documentos
- SEMPRE fundamente tecnicamente seus argumentos
- Use dispositivos legais completos (Lei n¬∫ X, art. Y, ¬ß Z)
- Cite jurisprud√™ncia quando houver (STF, STJ, TJMS)
- Mantenha tom formal e respeitoso
"""
    
    async def processar_processo(
        self,
        numero_cnj: str,
        numero_cnj_formatado: str = None,
        tipo_peca: Optional[str] = None,
        resposta_usuario: Optional[str] = None,
        usuario_id: int = None,
        documentos_resumo: Optional[str] = None,
        documentos_completos: Optional[str] = None,
        usar_agentes: bool = True
    ) -> Dict:
        """
        Processa um processo e gera a pe√ßa jur√≠dica usando os 3 agentes.

        Fluxo com agentes (usar_agentes=True):
        1. Agente 1 (TJ-MS): Baixa documentos e gera resumo consolidado
        2. Agente 2 (Detector): Analisa resumo e ativa m√≥dulos relevantes
        3. Agente 3 (Gemini 3 Pro): Gera a pe√ßa jur√≠dica final

        Args:
            numero_cnj: N√∫mero do processo sem formata√ß√£o
            numero_cnj_formatado: N√∫mero formatado para exibi√ß√£o
            tipo_peca: Tipo de pe√ßa a gerar (contestacao, recurso_apelacao, etc)
            resposta_usuario: Resposta a uma pergunta anterior
            usuario_id: ID do usu√°rio
            documentos_resumo: Resumo dos documentos (bypass do Agente 1)
            documentos_completos: Texto completo dos documentos (opcional)
            usar_agentes: Se True, usa o fluxo completo com 3 agentes
        """
        try:
            # Normaliza o CNJ
            cnj_limpo = re.sub(r'\D', '', numero_cnj)
            cnj_display = numero_cnj_formatado or numero_cnj

            # Debug
            orq_disponivel = _carregar_orquestrador()
            print(f"[DEBUG] Debug: usar_agentes={usar_agentes}, orquestrador={self.orquestrador is not None}, ORQUESTRADOR_DISPONIVEL={orq_disponivel}")

            # Se tem orquestrador e usar_agentes est√° ativo, usa o novo fluxo
            if usar_agentes and self.orquestrador and orq_disponivel:
                return await self._processar_com_agentes(
                    numero_cnj=cnj_limpo,
                    numero_cnj_formatado=cnj_display,
                    tipo_peca=tipo_peca or resposta_usuario,
                    usuario_id=usuario_id
                )

            # Fallback: modo legado (sem integra√ß√£o TJ-MS)
            return await self._processar_modo_legado(
                numero_cnj=cnj_limpo,
                numero_cnj_formatado=cnj_display,
                tipo_peca=tipo_peca,
                resposta_usuario=resposta_usuario,
                usuario_id=usuario_id,
                documentos_resumo=documentos_resumo,
                documentos_completos=documentos_completos
            )
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {
                "status": "erro",
                "mensagem": str(e)
            }
    
    async def _processar_com_agentes(
        self,
        numero_cnj: str,
        numero_cnj_formatado: str,
        tipo_peca: Optional[str],
        usuario_id: int
    ) -> Dict:
        """
        Processa usando os 3 agentes integrados.
        """
        print("\nIniciando processamento com 3 agentes...")
        print(f"   Processo: {numero_cnj_formatado}")
        
        # Executa o orquestrador (passa n√∫mero limpo, sem formata√ß√£o)
        resultado = await self.orquestrador.processar_processo(
            numero_processo=numero_cnj,  # N√∫mero sem formata√ß√£o (s√≥ d√≠gitos)
            tipo_peca=tipo_peca
        )
        
        # Trata resultado de pergunta
        if resultado.status == "pergunta":
            return {
                "status": "pergunta",
                "pergunta": resultado.pergunta,
                "opcoes": resultado.opcoes,
                "mensagem": resultado.mensagem
            }
        
        # Trata erro
        if resultado.status == "erro":
            return {
                "status": "erro",
                "mensagem": resultado.mensagem
            }
        
        # Sucesso - salva no banco
        # NOTA: Agora o conte√∫do √© diretamente em Markdown, n√£o mais JSON
        minuta_markdown = resultado.conteudo_markdown

        # Extrai dados para auditoria
        dados_extracao = None
        if resultado.agente1:
            try:
                from sistemas.gerador_pecas.orquestrador_agentes import consolidar_dados_extracao
                dados_extracao = consolidar_dados_extracao(resultado.agente1)
            except Exception:
                pass  # Se falhar, n√£o √© cr√≠tico

        # Salva no banco (incluindo prompt e resumo para auditoria)
        # conteudo_gerado agora armazena a string markdown diretamente

        # Calcula tempo de processamento (usa tempo_total ou soma dos tempos individuais)
        tempo_total = resultado.tempo_total
        if not tempo_total or tempo_total == 0.0:
            # Fallback: soma tempos individuais dos agentes
            tempo_total = (
                (resultado.tempo_agente1 or 0.0) +
                (resultado.tempo_agente2 or 0.0) +
                (resultado.tempo_agente3 or 0.0)
            )
        tempo_processamento = int(tempo_total) if tempo_total > 0 else None
        print(f"[DEBUG] tempo_total: {resultado.tempo_total}, tempos individuais: a1={resultado.tempo_agente1}, a2={resultado.tempo_agente2}, a3={resultado.tempo_agente3}, final={tempo_processamento}")

        geracao = GeracaoPeca(
            numero_cnj=numero_cnj,
            numero_cnj_formatado=numero_cnj_formatado,
            tipo_peca=resultado.tipo_peca,
            dados_processo=dados_extracao,  # Persiste vari√°veis extra√≠das para auditoria
            conteudo_gerado=minuta_markdown,  # Agora √© markdown string, n√£o JSON dict
            prompt_enviado=resultado.agente3.prompt_enviado if resultado.agente3 else None,
            resumo_consolidado=resultado.agente1.resumo_consolidado if resultado.agente1 else None,
            modelo_usado=self.modelo,
            tempo_processamento=tempo_processamento,
            usuario_id=usuario_id
        )

        # Campos de modo de ativa√ß√£o (podem n√£o existir no banco se migration pendente)
        # Atribu√≠dos ap√≥s cria√ß√£o para permitir fallback
        try:
            geracao.modo_ativacao_agente2 = resultado.agente2.modo_ativacao if resultado.agente2 else None
            geracao.modulos_ativados_det = resultado.agente2.modulos_ativados_det if resultado.agente2 else None
            geracao.modulos_ativados_llm = resultado.agente2.modulos_ativados_llm if resultado.agente2 else None
        except AttributeError:
            # Colunas n√£o existem no modelo (improv√°vel, mas defensivo)
            pass

        if self.db:
            try:
                self.db.add(geracao)
                self.db.commit()
                self.db.refresh(geracao)
            except Exception as e:
                # Se falhou por colunas inexistentes, tenta sem os campos de modo de ativa√ß√£o
                if 'modo_ativacao_agente2' in str(e) or 'modulos_ativados' in str(e):
                    self.db.rollback()
                    # Remove os campos problem√°ticos e tenta novamente
                    geracao.modo_ativacao_agente2 = None
                    geracao.modulos_ativados_det = None
                    geracao.modulos_ativados_llm = None
                    # For√ßa exclus√£o dos campos do estado do objeto
                    from sqlalchemy import inspect
                    state = inspect(geracao)
                    for attr in ['modo_ativacao_agente2', 'modulos_ativados_det', 'modulos_ativados_llm']:
                        if attr in state.dict:
                            del state.dict[attr]
                    self.db.add(geracao)
                    self.db.commit()
                    self.db.refresh(geracao)
                else:
                    raise
        
        # NOTA: Gera√ß√£o de DOCX desabilitada temporariamente para novo fluxo markdown
        # O DOCX ser√° implementado com conversor MD->DOCX no futuro
        # Por enquanto, o usu√°rio pode copiar o markdown e colar no Word
        
        return {
            "status": "sucesso",
            "geracao_id": geracao.id if self.db else None,
            "url_download": None,  # DOCX temporariamente desabilitado para novas gera√ß√µes
            "tipo_peca": resultado.tipo_peca,
            "conteudo_json": None,  # N√£o h√° mais JSON
            "minuta_markdown": minuta_markdown,
            "tempo_total": resultado.tempo_total
        }
    
    async def _processar_modo_legado(
        self,
        numero_cnj: str,
        numero_cnj_formatado: str,
        tipo_peca: Optional[str],
        resposta_usuario: Optional[str],
        usuario_id: int,
        documentos_resumo: Optional[str],
        documentos_completos: Optional[str]
    ) -> Dict:
        """
        Modo legado: sem integra√ß√£o com TJ-MS (documento de exemplo em Markdown).
        Se tipo_peca n√£o for especificado e h√° documentos_resumo, tenta detectar automaticamente.
        """
        print("[WARN] Usando modo legado (sem integracao TJ-MS)")

        tipo_final = tipo_peca or resposta_usuario

        # Se n√£o tem tipo de pe√ßa, tenta detectar automaticamente se h√° documentos
        if not tipo_final and self.detector and documentos_resumo:
            print("[INFO] Detectando tipo de peca automaticamente (modo legado)...")
            try:
                deteccao = await self.detector.detectar_tipo_peca(documentos_resumo)
                tipo_final = deteccao.get("tipo_peca")
                if tipo_final:
                    print(f"Tipo detectado: {tipo_final} (confianca: {deteccao.get('confianca', 'N/A')})")
            except Exception as e:
                print(f"[WARN] Erro na deteccao automatica: {e}")

        # Se ainda n√£o tem tipo de pe√ßa, pergunta ao usu√°rio
        if not tipo_final:
            return {
                "status": "pergunta",
                "pergunta": f"Qual tipo de pe√ßa jur√≠dica voc√™ deseja gerar para o processo {numero_cnj_formatado or numero_cnj}?",
                "opcoes": ["contestacao", "recurso_apelacao", "contrarrazoes", "parecer"],
                "mensagem": "N√£o foi poss√≠vel detectar automaticamente. Por favor, selecione o tipo de pe√ßa."
            }

        # Monta o prompt usando m√≥dulos (para auditoria)
        prompt_sistema = self._montar_prompt_sistema(
            tipo_final,
            modulos_ids=None,
            group_id=self.group_id,
            subcategoria_ids=self.subcategoria_ids
        )
        
        # Gera documento de exemplo em Markdown
        minuta_markdown = self._gerar_documento_exemplo_markdown(numero_cnj_formatado or numero_cnj, tipo_final)
        
        # Salva no banco
        geracao = GeracaoPeca(
            numero_cnj=numero_cnj,
            numero_cnj_formatado=numero_cnj_formatado,
            tipo_peca=tipo_final,
            conteudo_gerado=minuta_markdown,  # Agora √© Markdown string
            modelo_usado=self.modelo,
            usuario_id=usuario_id
        )
        
        if self.db:
            self.db.add(geracao)
            self.db.commit()
            self.db.refresh(geracao)
        
        return {
            "status": "sucesso",
            "geracao_id": geracao.id if self.db else None,
            "tipo_peca": tipo_final,
            "minuta_markdown": minuta_markdown
        }
    
    def _gerar_documento_exemplo_markdown(self, numero_cnj: str, tipo_peca: str) -> str:
        """Gera documento de exemplo em Markdown para demonstra√ß√£o"""
        
        tipo_labels = {
            "contestacao": "CONTESTA√á√ÉO",
            "recurso_apelacao": "RECURSO DE APELA√á√ÉO",
            "contrarrazoes": "CONTRARRAZ√ïES DE RECURSO",
            "parecer": "PARECER JUR√çDICO"
        }
        
        titulo = tipo_labels.get(tipo_peca, "PE√áA JUR√çDICA")
        
        return f"""**EXCELENT√çSSIMO SENHOR DOUTOR JUIZ DE DIREITO DA ___ VARA C√çVEL DA COMARCA DE CAMPO GRANDE - MS**

Processo n¬∫ {numero_cnj}

O **ESTADO DE MATO GROSSO DO SUL**, pessoa jur√≠dica de direito p√∫blico interno, inscrito no CNPJ sob o n¬∫ 15.412.257/0001-28, por meio de sua Procuradoria-Geral, vem, respeitosamente, √† presen√ßa de Vossa Excel√™ncia, apresentar a presente **{titulo}**, pelos fundamentos de fato e de direito a seguir expostos.

## I - DOS FATOS

Trata-se de a√ß√£o judicial em que o Estado de Mato Grosso do Sul figura no polo passivo. *[DESCRI√á√ÉO DOS FATOS SER√Å INSERIDA AQUI COM BASE NOS DOCUMENTOS DO PROCESSO]*

## II - DO DIREITO

*[FUNDAMENTA√á√ÉO JUR√çDICA SER√Å INSERIDA AQUI COM BASE NA AN√ÅLISE DO PROCESSO]*

> A jurisprud√™ncia do Superior Tribunal de Justi√ßa √© pac√≠fica no sentido de que a responsabilidade civil do Estado, embora objetiva, exige a comprova√ß√£o do nexo de causalidade entre a conduta estatal e o dano alegado.
> ‚Äî STJ, AgRg no AREsp 123.456/MS

## III - DOS PEDIDOS

Ante o exposto, requer seja julgado **improcedente** o pedido formulado na inicial, condenando-se a parte autora ao pagamento das custas processuais e honor√°rios advocat√≠cios.

---

*Campo Grande/MS, {datetime.now().strftime('%d de %B de %Y')}*

**[NOME DO PROCURADOR]**
Procurador do Estado
OAB/MS n¬∫ [N√öMERO]
"""

    async def editar_minuta(
        self,
        minuta_atual: str,
        mensagem_usuario: str,
        historico: List[Dict] = None
    ) -> Dict:
        """
        Processa pedido de edi√ß√£o da minuta via chat usando IA.
        
        Args:
            minuta_atual: Markdown da minuta atual
            mensagem_usuario: Pedido de altera√ß√£o do usu√°rio
            historico: Hist√≥rico de mensagens anteriores do chat
            
        Returns:
            Dict com status e minuta atualizada
        """
        from sistemas.gerador_pecas.gemini_client import chamar_gemini_async
        
        try:
            # Monta o prompt de sistema para edi√ß√£o
            system_prompt = """Voc√™ √© um assistente jur√≠dico especializado em edi√ß√£o de pe√ßas jur√≠dicas.

Sua fun√ß√£o √© modificar a minuta fornecida de acordo com o pedido do usu√°rio.

REGRAS IMPORTANTES:
1. Retorne APENAS a minuta editada em markdown, sem explica√ß√µes adicionais
2. Mantenha a formata√ß√£o formal juridica
3. Preserve as partes que n√£o foram solicitadas para altera√ß√£o
4. Use markdown correto (## para t√≠tulos, **negrito**, *it√°lico*, > para cita√ß√µes)
5. Se o pedido n√£o for claro, fa√ßa a melhor interpreta√ß√£o poss√≠vel
6. Mantenha o tom formal e t√©cnico-jur√≠dico

N√ÉO inclua:
- Explica√ß√µes sobre as altera√ß√µes
- Coment√°rios sobre o documento
- Texto como "Aqui est√° a minuta editada"

Retorne SOMENTE a minuta editada em markdown."""

            # Monta o prompt do usu√°rio com hist√≥rico
            prompt_parts = []
            
            # Adiciona hist√≥rico se houver
            if historico:
                prompt_parts.append("### Hist√≥rico da conversa:")
                for msg in historico:
                    role = "Usu√°rio" if msg.get("role") == "user" else "Assistente"
                    prompt_parts.append(f"{role}: {msg.get('content', '')}")
                prompt_parts.append("")
            
            # Adiciona a mensagem atual com a minuta
            prompt_parts.append(f"""### Minuta atual:

{minuta_atual}

---

### Pedido de altera√ß√£o: {mensagem_usuario}""")
            
            prompt_completo = "\n".join(prompt_parts)
            
            # Logging para diagn√≥stico
            prompt_len = len(prompt_completo)
            print(f"[EDITAR] üìù Prompt de edi√ß√£o: {prompt_len:,} chars (~{prompt_len//4:,} tokens est.)")
            
            # Chama a IA com limite alto de tokens para suportar minutas grandes
            minuta_editada = await chamar_gemini_async(
                prompt=prompt_completo,
                system_prompt=system_prompt,
                modelo=self.modelo,
                max_tokens=50000,  # Limite alto para minutas jur√≠dicas extensas
                temperature=0.3
            )
            
            # Remove poss√≠veis blocos de c√≥digo markdown que a IA pode ter adicionado
            if minuta_editada.startswith('```markdown'):
                minuta_editada = minuta_editada[11:]
            if minuta_editada.startswith('```'):
                minuta_editada = minuta_editada[3:]
            if minuta_editada.endswith('```'):
                minuta_editada = minuta_editada[:-3]
            
            minuta_editada = minuta_editada.strip()

            return {
                "status": "sucesso",
                "minuta_markdown": minuta_editada
            }

        except httpx.HTTPStatusError as e:
            print(f"[ERRO] Erro HTTP na edicao: {e}")
            return {
                "status": "erro",
                "mensagem": f"Erro na comunica√ß√£o com a IA: {e.response.status_code}"
            }
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {
                "status": "erro",
                "mensagem": str(e)
            }

    async def editar_minuta_stream(
        self,
        minuta_atual: str,
        mensagem_usuario: str,
        historico: List[Dict] = None
    ):
        """
        Processa edi√ß√£o da minuta com streaming real.

        PERFORMANCE: Usa streamGenerateContent do Gemini para enviar
        tokens assim que s√£o gerados, reduzindo TTFT de 15-60s para 1-3s.

        Args:
            minuta_atual: Markdown da minuta atual
            mensagem_usuario: Pedido de altera√ß√£o do usu√°rio
            historico: Hist√≥rico de mensagens anteriores

        Yields:
            Chunks de texto conforme s√£o gerados
        """
        from services.gemini_service import gemini_service

        # Monta o prompt de sistema para edi√ß√£o
        system_prompt = """Voc√™ √© um assistente jur√≠dico especializado em edi√ß√£o de pe√ßas jur√≠dicas.

Sua fun√ß√£o √© modificar a minuta fornecida de acordo com o pedido do usu√°rio.

REGRAS IMPORTANTES:
1. Retorne APENAS a minuta editada em markdown, sem explica√ß√µes adicionais
2. Mantenha a formata√ß√£o formal juridica
3. Preserve as partes que n√£o foram solicitadas para altera√ß√£o
4. Use markdown correto (## para t√≠tulos, **negrito**, *it√°lico*, > para cita√ß√µes)
5. Se o pedido n√£o for claro, fa√ßa a melhor interpreta√ß√£o poss√≠vel
6. Mantenha o tom formal e t√©cnico-jur√≠dico

N√ÉO inclua:
- Explica√ß√µes sobre as altera√ß√µes
- Coment√°rios sobre o documento
- Texto como "Aqui est√° a minuta editada"

Retorne SOMENTE a minuta editada em markdown."""

        # Monta o prompt do usu√°rio com hist√≥rico
        prompt_parts = []

        # Adiciona hist√≥rico se houver
        if historico:
            prompt_parts.append("### Hist√≥rico da conversa:")
            for msg in historico:
                role = "Usu√°rio" if msg.get("role") == "user" else "Assistente"
                prompt_parts.append(f"{role}: {msg.get('content', '')}")
            prompt_parts.append("")

        # Adiciona a mensagem atual com a minuta
        prompt_parts.append(f"""### Minuta atual:

{minuta_atual}

---

### Pedido de altera√ß√£o: {mensagem_usuario}""")

        prompt_completo = "\n".join(prompt_parts)

        # Logging para diagn√≥stico
        prompt_len = len(prompt_completo)
        print(f"[EDITAR STREAM] üìù Prompt: {prompt_len:,} chars (~{prompt_len//4:,} tokens est.)")

        # Usa streaming real do Gemini
        async for chunk in gemini_service.generate_stream(
            prompt=prompt_completo,
            system_prompt=system_prompt,
            model=self.modelo,
            max_tokens=50000,
            temperature=0.3,
            context={"sistema": "gerador_pecas", "modulo": "editar_minuta"}
        ):
            yield chunk
